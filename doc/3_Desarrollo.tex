%!TEX root = main.tex

\chapter{Desarrollo de la solución}\label{c:desarrollo}

Para el análisis de los datos requeridos por los usuarios de DrugBank se contó
con los archivos de registro, en los cuales se mantienen tanto las consultas
como metadatos de ellas.
Con la información disponible, el proceso para calcular la
centralidad de los datos se estructura como sigue, en la sección~\ref{d:emc}
se describe cómo se extrajeron las consultas y cómo fueron modificadas para
retornar los triples utilizados. En la sección~\ref{d:cg} se presenta el modelo
utilizado para transformar la base de datos RDF a un grafo sobre el cual
calcular la centralidad y en la sección~\ref{d:cc} se explica el algoritmo
usado para éste cálculo.

\section{Extracción y modificación de consultas}\label{d:emc}
Los archivos de registro analizados están codificados en formato \tt{json},
cada linea es un diccionario con los siguientes elementos (entre otros):
\begin{itemize}
  \item
    Los atributos \tt{DESCRIBE}, \tt{CONSTRUCT}, \tt{SELECT} y \tt{ASK} serán
    $1$ si la consulta es de ese tipo, $0$ si no lo es y una cadena de
    caracteres vacía si ocurrió un error.
  \item
    El atributo \tt{ip} guarda la IP que generó la consulta.
  \item
    El atributo \tt{query} guarda la consulta completa en una cadena de
    caracteres. 
  \item
    El atributo \tt{targer\_endpoint} guarda la \tt{url} del \tt{endpoint}
    objetivo.
  \item
    El atributo \tt{date} guarda la fecha y hora en las cuales se registró la
    consulta.
  \item
    El atributo \tt{response\_size} guarda la cantidad de bytes generados por la
    consulta.
  \item
    El atributo \tt{error} será \tt{true} si la consulta no fue procesada con
    éxito.
\end{itemize}

Con base en las consultas guardadas en estos archivos se busca generar sus
equivalentes en \tt{CONSTRUCT} de manera que estos retornen los mismos triples
que son consultados en el servidor.
Debemos tener en cuenta que operaciones como \tt{AND} y \tt{UNION} son
conmutativas y asociativas, pero \tt{OPTIONAL} requerirá un tratamiento especial
al transformar las consultas (\cite{perez2006semantics}).

Para este proceso se ignoraron tanto las consultas con atributos \tt{ASK} o
\tt{DESCRIBE} distintos de $0$, además de aquellas con el atributo \tt{error}
como \tt{true}.

Las consultas que pasan este filtro siguen el siguiente procedimiento:
\begin{enumerate}
  \item
    Se analiza la cadena de caracteres y se separa en las siguientes partes:
    \begin{enumerate}
      \item
        \tt{head}: Guarda el prólogo de la consulta (\tt{PREFIX} y \tt{BASE})
      \item
        \tt{qtype}: Guarda el tipo de consulta y sus parámetros, es decir
        \tt{SELECT} o \tt{CONSTRUCT} junto a la tabla o triples que los
        acompañan respectivamente.
      \item
        \tt{where}: Guarda la sección \tt{WHERE} de la consulta, todos los
        triples y operaciones hechas para la búsqueda están en esta sección.
      \item
        \tt{tail}: Guarda la parte final de la consulta, los modificadores de la
        solución, por ejemplo \tt{LIMIT}, \tt{ORDER} u \tt{OFFSET}.
    \end{enumerate}
  \item
    Se hace una búsqueda en la sección \tt{where} de la consulta para encontrar
    todos los triples requeridos. En este proceso se recurre a la comparación de
    cadenas de caracteres, donde se separan las URIs e inmutables (comillas
    dobles o simples o tres de alguna de éstas), de los separadores de triples
    (como ``\tt{.}'', ``\tt{;}'' o ``\tt{,}'') y otras operaciones (como
    \tt{FILTER},    \tt{SERVICE} u \tt{OPTIONAL}).
  \item
    La búsqueda se hace recursivamente para encontrar los triples dentro de
    estructuras más complejas como son \tt{UNION} o \tt{GRAPH}.
  \item
    Algunas consultas requieren recursos anónimos. En este caso, los
    caracteres ``\lbrack'', ``\rbrack'' o ``/'' fueron remplazados por variables
    con nombre.
  \item
    Los triples que eran parte de clausulas opcionales también fueron extraídos,
    pero guardados separadamente. Cada clausula opcional genera su propia lista
    de triples.
    Debido a que un \tt{CONSTRUCT} simple ignoraría estos atributos.
  \item
    Por los alcances propios de el proyecto las consultas con la operación
    \tt{SERVICE} o consultas anidadas no fueron analizadas.
\end{enumerate}

Una vez terminado este proceso se tiene tanto la consulta completa como una
lista con todos sus triples y cero o más listas con triples opcionales.
Con esta información se procede a generar la consulta tipo \tt{CONSTRUCT}
resultantes como sigue:
\begin{enumerate}
  \item
    Para las consultas sin \tt{OPTIONAL} se modifica solo la parte \tt{qtype}
    generando un \tt{CONSTRUCT} con los triples obtenidos de la búsqueda en
    \tt{where}.
  \item
    Para las consultas con \tt{OPTIONAL} se genera la consulta descrita en el
    punto anterior y una consulta más por cada clausula opcional haciendo esta
    misma obligatoria, de esta forma se obtendrán la mayor cantidad de datos
    que la consulta puede retornar.
    La correctitud de los datos obtenidos por esta operación es demostrada
		en~\cite{perez2006semantics}.
\end{enumerate}

El algoritmo~\ref{alg:extract} muestra el pseudo código para todo este
procedimiento. Mientras que la figura~\ref{fig:exextr} muestra un ejemplo de
su funcionamiento.

%105.158.161.3
\input{code/example-consults}

En la figura~\ref{fig:exextr:or} se muestra la consulta original la cual,
después del procesamiento, generará 3 consultas, todas ellas reemplazando su
tercera linea. Para la primera consulta se reemplazará por el \tt{CONSTRUCT} de
la figura~\ref{fig:exextr:1}, en la segunda por el de~\ref{fig:exextr:2} y en la
tercera por el de~\ref{fig:exextr:3}.

\input{code/extract_query}

El programa creado siguiendo el algoritmo~\ref{alg:extract} tiene la capacidad
de analizar uno o más archivos con cualquier cantidad de lineas
(cada una es un registro de consulta).
Los resultados serán guardados en un archivo por dirección IP donde cada linea
representa una consulta resultante.

El programa también provee la opción de ingresar un tamaño máximo de la 
respuesta obtenida (\tt{--max}) de manera que se revise el atributo 
\tt{response\_size} y si este supera el máximo definido, la consulta se guarda
en un archivo aparte.
Además se agrega la opción de filtrar por \it{endpoint} (\tt{--endpoint}) para 
solo analizar aquellas consultas que se hicieron a dicha dirección.

Para prevenir la realización de consultas que retornen toda la base de datos se
agregó un filtro de manera de separar (en otro archivo) aquellas que solo
contienen variables en su parte \tt{CONSTRUCT}. Un ejemplo de ello es la
consulta de la figura~\ref{fig:exbigq}.

\begin{figure}[ht]
  \centering
  \tt{CONSTRUCT \{ ?a ?b ?c . \} WHERE \{ ?a ?b ?c . \}}
  \caption{Consulta que retornará toda la base de datos.}\label{fig:exbigq}
\end{figure}

Por otro lado todas las operaciones realizadas por el programa son debidamente
regis-tradas en un archivo (\tt{log}) de manera que si ocurre algún error se
pueda determinar su causa. En este archivo además se registra la fuente y el
destino de todas las consultas analizadas.

De la ejecución del programa en todos los registros se generan 
archivos que contienen todas las consultas de cada IP. Con las
consultas ya modificadas resta ejecutarlas en el \tt{endpoint} de DrugBank y
obtener los datos buscados.

\section{Creación del grafo}\label{d:cg}
Para obtener los resultados se utilizó un servidor
\emph{Virtuoso\footnote{\url{http://virtuoso.openlinksw.com/}} v7.2.1} montado 
localmente cargado con los últimos datos disponibles de
DrugBank\footnote{\url{http://download.bio2rdf.org/release/4/drugbank/}}.
Al ejecutar todas las consultas localmente no se pierde tiempo en la
transferencia de datos por Internet ni tenemos las limitaciones que un servidor
externo podría imponernos. 

Como la cantidad de consultas es muy grande se generó un \it{script} en
\it{python} que tiene las siguientes funcionalidades (entre otras):
\begin{itemize}
  \item
    Ejecuta la consulta en el \tt{endpoint} seleccionado y,
  \item
    Si se retornaron triples, estos se guardan al final de un archivo que tiene
    por nombre la dirección IP y por extensión \tt{.nt}.
  \item
    Si ocurrió un error, se registra el nombre del archivo, la linea que lo
    causó y el código de error en un archivo llamado \tt{error\_query}.
  \item
    Si el retorno es vacío (\tt{\# Empty NT}), se guarda el nombre y la linea que
    lo generó en un archivo llamado \tt{empty\_query}.
\end{itemize}

Después de ejecutar el \it{script} sobre todas las consultas generadas en la
sección~\ref{d:emc} tendremos un archivo con extensión \tt{.nt} por IP
con los resultados.
Este archivo muy posiblemente tenga triples repetidos los cuales son inútiles
para este estudio.

Para generar el subconjunto de datos consultados por los usuarios, se utilizó el
siguiente comando en el \it{shell} de \it{linux}.
$$\tt{\$ cat *.nt | sort -u > all.nt }$$

El programa \tt{cat}\footnote{
  \url{http://manpages.ubuntu.com/manpages/xenial/en/man1/cat.1.html}} 
concatena e imprime el contenido de todos los archivos que
son pasados como argumento, en este caso \tt{*.nt} que representa todos los
archivos que terminen en \tt{.nt}, es decir todos los resultados de las
consultas.
Éste resultado se pasa al programa \tt{sort}\footnote{
  \url{http://manpages.ubuntu.com/manpages/xenial/en/man1/sort.1.html}}
que se encarga de ordenar la entrada dependiendo del argumento seleccionado, en
este caso \tt{-u}, \tt{unique}, lo que le indica descartar todas las lineas
duplicadas. Por último se redirige la salida estándar a un archivo llamado
\tt{all.nt}.

Ahora que se tienen todos los resultados encontrados en un único archivo
N-Triples del cual se generará el grafo que los representa.
Para ello se utiliza la siguiente técnica:

Recordemos que todo triple RDF tiene el formato descrito en la
sección~\ref{sw:rdf}: $\langle s,p,o\rangle$
donde $p$ es la relación existente entre $s$ y $o$. Una forma natural de
representar el triple como grafo será la mostrada en la
figura~\ref{fig:rdfgraphsimple}.

\begin{figure}[htpb]
  \centering
  \begin{tikzpicture}
    \begin{scope}[every node/.style={circle,thick,draw}]
      \node (s) at (0,0)    {$s$};
      \node (o) at (4,0)    {$o$};
    \end{scope}
    \begin{scope}[>={Stealth[black]},every edge/.style={draw=black,very thick}]
      \path[->] (s) edge node[above] {$p$} (o);
    \end{scope}
  \end{tikzpicture}
  \caption{Triple RDF como grafo.}
  \label{fig:rdfgraphsimple}
\end{figure}

Si bien ésta representación es simple, puede ser reducida aún más teniendo en
cuenta que para el calculo de centralidad no importa realmente cual es la
relación entre $s$ y $o$, solo es necesario que exista. Así, ignorando $p$ para
todo triple y eliminando duplicados podemos generar un digrafo con arcos sin
pesos el cual será ideal para calcular la centralidad.

El elemento $s$ puede ser una URI o un recurso anónimo, mientras que $o$ además
puede ser un literal. De cualquier forma su identificador en el archivo \tt{nt}
será una cadena de caracteres, esto es un gasto de memoria innecesario para el
calculo de la centralidad y por ello es mejor asignar un entero identificador 
(\it{id}) a cada recurso $s$ y $o$.

Teniendo en cuenta que en un archivo N-Triples cada linea utiliza el mismo
formato para representar un triple (\verb$STRING\tSTRING\tSTRING .\n$) se hace
fácil generar un conversor desde N-Triples a un grafo donde todo nodo es
identificado por una \tt{id} y una lista de nodos adyacentes.
Este proceso se describe en el algoritmo~\ref{alg:convert}.

\input{code/simple_converter}

En este algoritmo se tratan indistintamente tanto URIs como recursos anónimos y
literales debido a que todos ellos son cadenas de caracteres con
diferentes formatos.

La figura~\ref{fig:nt-to-graph} muestra un ejemplo de este proceso.
En~\ref{fig:nt:orig} se muestra la versión N~-Triples\footnote{Prefijos omitidos
por conveniencia} de la figura~\ref{fig:triples:ttl}.
Después de ejecutar el algoritmo~\ref{alg:convert} los archivo resultantes serán
el grafo como listas de adyacencia (figura~\ref{fig:nt:sg}) y el archivo con los
nombres (figura~\ref{fig:nt:names}). Por último la figura\ref{fig:nt:graph} es
la representación gráfica del archivo \tt{.sg}.

\input{code/example-nt-to-graph}

Aplicando este proceso a los datos obtenidos obtendremos un grafo al cual nos
basta calcular la centralidad.

\section{Calculo de centralidad}\label{d:cc}
Para este trabajo se considera interesante conocer la centralidad de grado y la
intermediación. Se calcula la centralidad de grado pues es la medida más simple
para verificar cuales son los nodos más consultados por los usuarios. Por otro
lado el cálculo de la intermediación nos dará una medida de la influencia de
cada nodo como nexo entre diferentes entidades.

\subsection{Centralidad de grado}
Como vimos en la sección~\ref{ea:cent:degree} la centralidad de grado tiene una
complejidad computacional de $\Theta (E)$ por ello puede ser fácilmente obtenida
mientras se lee el archivo que almacena el grafo. El algoritmo~\ref{alg:degree}
describe este proceso.

\input{code/degree_centrality}

Lo más costoso de este procedimiento es el proceso de lectura del archivo que
contiene la información y la escritura de los resultados, por ello,
no hay mucho que podamos hacer para optimizarlo,
aún así es un proceso bastante rápido.

\subsection{Intermediación}
Con los datos ya cargados debemos calcular la intermediación. En la
sección~\ref{ea:cent:bet} se muestra como éste proceso es generalmente de
complejidad $\Theta (V^3)$, pero gracias a las
características del grafo que generamos, podemos utilizar el algoritmo de
Brandes\cite{brandes2001faster} de complejidad $O(VE)$.

Como se espera que el calculo se realice para un grafo con millones de nodos
necesitamos que el algoritmo sea lo más rápido posible, para ello la literatura
aporta con diferentes enfoques a la hora de paralelizar el calculo de la
intermediación. Un buen esquema con diversas formas de realizar esta
paralelización puede ser encontrado en el trabajo de Madduri
\etal\cite{madduri2009faster}, pero los algoritmos más rápidos necesitan de una
arquitectura con soporte para dos operaciones atómicas, las cuales no existen en
la maquina que se utilizó para hacer los cálculos.
Si bien se puede emular el comportamiento de dichas operaciones con semáforos
para su sincronización, el rendimiento sería peor que una paralelización
convencional.

Aún así, podemos hacer uso parcial de una paralelización de grano
fino\footnote{Con mucha comunicación entre las subtareas.} descrita
en~\cite{bader2006parallel}. Éste algoritmo toma en cuenta tanto el tiempo de
ejecución como la memoria utilizada, pero en nuestro caso, debido a las
características que la maquina que se posee, nos importa más la minimización
del tiempo, por lo que, para reducir los costos de sincronización y así el
tiempo total, se replica la memoria utilizada para los cálculos generando un
algoritmo con paralelización a grano grueso.

Como el algoritmo de Brandes calcula la intermediación a través de acumulación
de dependencia, será lo mismo calcular la centralidad de todos los nodos que
calcular por nodo y luego sumar los totales.
Tomando esta idea, calcularemos la intermediación total del grafo como la suma
del aporte de la dependencia acumula de cierto número de conjuntos de nodos
(sub-grafos) al grafo total.

El algoritmo~\ref{alg:bet} describe el proceso que debe seguir cada sub-grafo
para obtener su aporte a la centralidad total. Esta tarea puede ser ejecutada
paralelamente pues todos los datos generados son locales.
Al finalizar las tareas se debe sumar sus resultados.

Considerando un computador con $N$ procesadores, si el grafo es denso podemos
dividir el problema en $N$ sub-grafos, como cada sub-grafo debería tener más o
menos la misma cantidad de arcos (o al menos el mismo orden de magnitud)
cada tarea debería tardar tiempos similares, y, al realizarse en paralelo, el
tiempo total de ejecución no debería ser mucho mayor al tiempo de ejecución de
una tarea.

Por otro lado, si el grafo es disperso, dos sub-grafos con la misma cantidad de
nodos pueden tener cantidades muy diferentes de arcos y por ello será poco
probable que ambas tareas terminen en tiempos similares. Para minimizar el
impacto de esta situación tenemos dos opciones: Se pueden generar sub-grafos de
manera que el tiempo estimado de cálculo para cada uno de ellos sea similar,
lamentablemente este proceso es muy costoso.
La otra opción será dividir el grafo en un
número $M$ de sub-grafos de manera que $M > N$ y procesar solo $N$ tareas a la
vez, de esta forma, cuando una tarea termina, otra comenzará su ejecución y,
mientras no queden las tareas más demorosas al final, el tiempo total no será
tan dependiente de la subtarea más demorosa.

\input{code/betweenness_centrality}

Se intuye que un grafo RDF es generalmente disperso debido a que algunas 
relaciones están presentes en la mayoría de los triples y, por lo tanto, tendrán
muchos más arcos en el grafo que un individuo cualquiera. Se debe tomar en
consideración esta característica para determinar el número de sub-grafos a
generar para un calculo eficiente.
